{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix Self-Consistency Notebook \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama-hub/blob/main/llama_hub/llama_packs/tables/mix_slf_consistency/mix_self_consistency.ipynb\" target=\"_parent\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this notebook, we highlight the mix self-consistency method proposed in \"Rethinking Tabular Data Understanding with Large Language Models\" paper by Liu et al.[https://arxiv.org/pdf/2312.16702v1.pdf].\n",
    "\n",
    "LLMs can reason over tabular data in 2 main ways:\n",
    "1. textual reasoning via direct prompting\n",
    "2. symbolic reasoning via program synthesis (e.g. python, SQL, etc)\n",
    "\n",
    "The key insight of the paper is that different reasoning pathways work well in different tasks. By aggregating results from both with a self-consistency mechanism, it achieves SoTA performance.\n",
    "\n",
    "We implemented the paper based on the prompts described in the paper, and adapted it to get it working. That said, this is marked as beta, so there may still be kinks to work through. Do you have suggestions / contributions on how to improve the robustness? Let us know! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "\n",
    "We use the [WikiTableQuestions dataset](https://ppasupat.github.io/WikiTableQuestions/) (Pasupat and Liang 2015) as our test dataset.\n",
    "\n",
    "WikiTableQuestions is a question-answering dataset over various semi-structured tables taken from Wikipedia. These tables range in size from a few rows/columns to mnay rows. Some columns may contain multi-part information as well (e.g. a temperature column may contain both Fahrenheight and Celsius)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-14 11:30:51--  https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/82109896/b9b6aeb6-f3c1-11e6-9167-57b997906244?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T193052Z&X-Amz-Expires=300&X-Amz-Signature=1bd2daf88500682f44ddf871c0ee3908244da040168fe80b297a92718d2ae1c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=82109896&response-content-disposition=attachment%3B%20filename%3DWikiTableQuestions-1.0.2-compact.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-01-14 11:30:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/82109896/b9b6aeb6-f3c1-11e6-9167-57b997906244?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T193052Z&X-Amz-Expires=300&X-Amz-Signature=1bd2daf88500682f44ddf871c0ee3908244da040168fe80b297a92718d2ae1c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=82109896&response-content-disposition=attachment%3B%20filename%3DWikiTableQuestions-1.0.2-compact.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29267445 (28M) [application/octet-stream]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]  27.91M  27.3MB/s    in 1.0s    \n",
      "\n",
      "2024-01-14 11:30:53 (27.3 MB/s) - ‘data.zip’ saved [29267445/29267445]\n",
      "\n",
      "Archive:  data.zip\n",
      "replace WikiTableQuestions/evaluator.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\" -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visual some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>utterance</th>\n",
       "      <th>context</th>\n",
       "      <th>targetValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nt-0</td>\n",
       "      <td>what was the last year where this team was a p...</td>\n",
       "      <td>csv/204-csv/590.csv</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nt-1</td>\n",
       "      <td>in what city did piotr's last 1st place finish...</td>\n",
       "      <td>csv/204-csv/622.csv</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nt-2</td>\n",
       "      <td>which team won previous to crettyard?</td>\n",
       "      <td>csv/204-csv/772.csv</td>\n",
       "      <td>Wolfe Tones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nt-3</td>\n",
       "      <td>how many more passengers flew to los angeles t...</td>\n",
       "      <td>csv/203-csv/515.csv</td>\n",
       "      <td>12,467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nt-4</td>\n",
       "      <td>who was the opponent in the first game of the ...</td>\n",
       "      <td>csv/204-csv/495.csv</td>\n",
       "      <td>Derby County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          utterance  \\\n",
       "0  nt-0  what was the last year where this team was a p...   \n",
       "1  nt-1  in what city did piotr's last 1st place finish...   \n",
       "2  nt-2              which team won previous to crettyard?   \n",
       "3  nt-3  how many more passengers flew to los angeles t...   \n",
       "4  nt-4  who was the opponent in the first game of the ...   \n",
       "\n",
       "               context        targetValue  \n",
       "0  csv/204-csv/590.csv               2004  \n",
       "1  csv/204-csv/622.csv  Bangkok, Thailand  \n",
       "2  csv/204-csv/772.csv        Wolfe Tones  \n",
       "3  csv/203-csv/515.csv             12,467  \n",
       "4  csv/204-csv/495.csv       Derby County  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "examples = pd.read_table('WikiTableQuestions/data/training-before300.tsv')\n",
    "\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the table that can be used as context to answer the question in the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Division</th>\n",
       "      <th>League</th>\n",
       "      <th>Regular Season</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>Open Cup</th>\n",
       "      <th>Avg. Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>4th, Western</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>7,169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>2nd, Pacific</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>6,260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>3rd, Pacific</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>5,871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>1st, Western</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>USL First Division</td>\n",
       "      <td>5th</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>6,028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Division              League Regular Season         Playoffs  \\\n",
       "0  2001         2        USL A-League   4th, Western    Quarterfinals   \n",
       "1  2002         2        USL A-League   2nd, Pacific        1st Round   \n",
       "2  2003         2        USL A-League   3rd, Pacific  Did not qualify   \n",
       "3  2004         2        USL A-League   1st, Western    Quarterfinals   \n",
       "4  2005         2  USL First Division            5th    Quarterfinals   \n",
       "\n",
       "          Open Cup Avg. Attendance  \n",
       "0  Did not qualify           7,169  \n",
       "1  Did not qualify           6,260  \n",
       "2  Did not qualify           5,871  \n",
       "3        4th Round           5,628  \n",
       "4        4th Round           6,028  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = examples.iloc[0]\n",
    "table = pd.read_csv('WikiTableQuestions/' + example['context'])\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pack / Setup\n",
    "\n",
    "Now we do `download_llama_pack` to load the Mix Self Consistency LlamaPack (you can also import the module directly if using the llama-hub package).\n",
    "\n",
    "We will also optionally setup observability/tracing so we can observe the intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: if developing with the llama_hub package\n",
    "from llama_hub.llama_packs.tables.mix_self_consistency.base import (\n",
    "    MixSelfConsistencyQueryEngine,\n",
    ")\n",
    "\n",
    "# Option: download llama_pack\n",
    "# from llama_index.llama_pack import download_llama_pack\n",
    "\n",
    "# download_llama_pack(\n",
    "#     \"MixSelfConsistencyPack\",\n",
    "#     \"./mix_self_consistency_pack\",\n",
    "#     skip_load=True,\n",
    "#     # leave the below line commented out if using the notebook on main\n",
    "#     llama_hub_url=\"https://raw.githubusercontent.com/run-llama/llama-hub/suo/table_qa/llama_hub\"\n",
    "# )\n",
    "# from mix_self_consistency_pack.base import MixSelfConsistencyQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = MixSelfConsistencyQueryEngine(\n",
    "    table=table, \n",
    "    llm=llm,\n",
    "    text_paths=1,\n",
    "    symbolic_paths=1,\n",
    "    aggregation_mode='self_evaluation',\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module c043faaf-f87d-424a-b6e3-f711e77d06ed with input: \n",
      "question: what was the last year where this team was a part of the usl a-league?\n",
      "table: |    |   Year |   Division | League              | Regular Season   | Playoffs        | Open Cup        | Avg. Attendance   |\n",
      "|---:|-------:|-----------:|:--------------------|:-----------------|:----...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 6d7fe07e-4f32-4f87-bada-379c90d1a7ff with input: \n",
      "messages: You are an advanced AI capable of analyzing and understanding information within tables. Read the table below.\n",
      "\n",
      "|    |   Year |   Division | League              | Regular Season   | Playoffs        | ...\n",
      "\n",
      "\u001b[0m> Pandas Instructions:\n",
      "```\n",
      "`df[df['League'] == 'USL A-League']['Year'].max()`\n",
      "```\n",
      "> Pandas Output: There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/llama_index/query_engine/pandas_query_engine.py\", line 61, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "  File \"/Users/suo/miniconda3/envs/llama/lib/python3.9/ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "  File \"<unknown>\", line 1\n",
      "    `df[df['League'] == 'USL A-League']['Year'].max()`\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module 3fc7b970-7d46-4619-b7de-37344ad32d4c with input: \n",
      "input: assistant: To find the last year in which this team was a part of the USL A-League, we need to look for the rows where the \"League\" column mentions \"USL A-League.\" \n",
      "\n",
      "Looking at the table, we can see t...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='2004', source_nodes=[], metadata=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await query_engine.aquery(example['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
