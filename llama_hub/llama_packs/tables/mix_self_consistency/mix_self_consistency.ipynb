{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix Self-Consistency Notebook \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama-hub/blob/main/llama_hub/llama_packs/tables/mix_slf_consistency/mix_self_consistency.ipynb\" target=\"_parent\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this notebook, we highlight the mix self-consistency method proposed in \"Rethinking Tabular Data Understanding with Large Language Models\" paper by Liu et al.[https://arxiv.org/pdf/2312.16702v1.pdf].\n",
    "\n",
    "LLMs can reason over tabular data in 2 main ways:\n",
    "1. textual reasoning via direct prompting\n",
    "2. symbolic reasoning via program synthesis (e.g. python, SQL, etc)\n",
    "\n",
    "The key insight of the paper is that different reasoning pathways work well in different tasks. By aggregating results from both with a self-consistency mechanism, it achieves SoTA performance.\n",
    "\n",
    "We implemented the paper based on the prompts described in the paper, and adapted it to get it working. That said, this is marked as beta, so there may still be kinks to work through. Do you have suggestions / contributions on how to improve the robustness? Let us know! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "\n",
    "We use the [WikiTableQuestions dataset](https://ppasupat.github.io/WikiTableQuestions/) (Pasupat and Liang 2015) as our test dataset.\n",
    "\n",
    "WikiTableQuestions is a question-answering dataset over various semi-structured tables taken from Wikipedia. These tables range in size from a few rows/columns to mnay rows. Some columns may contain multi-part information as well (e.g. a temperature column may contain both Fahrenheight and Celsius)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-14 11:30:51--  https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/82109896/b9b6aeb6-f3c1-11e6-9167-57b997906244?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T193052Z&X-Amz-Expires=300&X-Amz-Signature=1bd2daf88500682f44ddf871c0ee3908244da040168fe80b297a92718d2ae1c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=82109896&response-content-disposition=attachment%3B%20filename%3DWikiTableQuestions-1.0.2-compact.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-01-14 11:30:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/82109896/b9b6aeb6-f3c1-11e6-9167-57b997906244?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T193052Z&X-Amz-Expires=300&X-Amz-Signature=1bd2daf88500682f44ddf871c0ee3908244da040168fe80b297a92718d2ae1c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=82109896&response-content-disposition=attachment%3B%20filename%3DWikiTableQuestions-1.0.2-compact.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29267445 (28M) [application/octet-stream]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]  27.91M  27.3MB/s    in 1.0s    \n",
      "\n",
      "2024-01-14 11:30:53 (27.3 MB/s) - ‘data.zip’ saved [29267445/29267445]\n",
      "\n",
      "Archive:  data.zip\n",
      "replace WikiTableQuestions/evaluator.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\" -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visual some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>utterance</th>\n",
       "      <th>context</th>\n",
       "      <th>targetValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nt-0</td>\n",
       "      <td>what was the last year where this team was a p...</td>\n",
       "      <td>csv/204-csv/590.csv</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nt-1</td>\n",
       "      <td>in what city did piotr's last 1st place finish...</td>\n",
       "      <td>csv/204-csv/622.csv</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nt-2</td>\n",
       "      <td>which team won previous to crettyard?</td>\n",
       "      <td>csv/204-csv/772.csv</td>\n",
       "      <td>Wolfe Tones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nt-3</td>\n",
       "      <td>how many more passengers flew to los angeles t...</td>\n",
       "      <td>csv/203-csv/515.csv</td>\n",
       "      <td>12,467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nt-4</td>\n",
       "      <td>who was the opponent in the first game of the ...</td>\n",
       "      <td>csv/204-csv/495.csv</td>\n",
       "      <td>Derby County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          utterance  \\\n",
       "0  nt-0  what was the last year where this team was a p...   \n",
       "1  nt-1  in what city did piotr's last 1st place finish...   \n",
       "2  nt-2              which team won previous to crettyard?   \n",
       "3  nt-3  how many more passengers flew to los angeles t...   \n",
       "4  nt-4  who was the opponent in the first game of the ...   \n",
       "\n",
       "               context        targetValue  \n",
       "0  csv/204-csv/590.csv               2004  \n",
       "1  csv/204-csv/622.csv  Bangkok, Thailand  \n",
       "2  csv/204-csv/772.csv        Wolfe Tones  \n",
       "3  csv/203-csv/515.csv             12,467  \n",
       "4  csv/204-csv/495.csv       Derby County  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "examples = pd.read_table('WikiTableQuestions/data/training-before300.tsv')\n",
    "\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the table that can be used as context to answer the question in the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = examples.iloc[0]\n",
    "table = pd.read_csv('WikiTableQuestions/' + example['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Division</th>\n",
       "      <th>League</th>\n",
       "      <th>Regular Season</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>Open Cup</th>\n",
       "      <th>Avg. Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>4th, Western</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>7,169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>2nd, Pacific</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>6,260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>3rd, Pacific</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>5,871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>USL A-League</td>\n",
       "      <td>1st, Western</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>USL First Division</td>\n",
       "      <td>5th</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>6,028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>USL First Division</td>\n",
       "      <td>11th</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>5,575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>USL First Division</td>\n",
       "      <td>2nd</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>2nd Round</td>\n",
       "      <td>6,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>USL First Division</td>\n",
       "      <td>11th</td>\n",
       "      <td>Did not qualify</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>8,567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>USL First Division</td>\n",
       "      <td>1st</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>9,734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>USSF D-2 Pro League</td>\n",
       "      <td>3rd, USL (3rd)</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>10,727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Division               League  Regular Season         Playoffs  \\\n",
       "0  2001         2         USL A-League    4th, Western    Quarterfinals   \n",
       "1  2002         2         USL A-League    2nd, Pacific        1st Round   \n",
       "2  2003         2         USL A-League    3rd, Pacific  Did not qualify   \n",
       "3  2004         2         USL A-League    1st, Western    Quarterfinals   \n",
       "4  2005         2   USL First Division             5th    Quarterfinals   \n",
       "5  2006         2   USL First Division            11th  Did not qualify   \n",
       "6  2007         2   USL First Division             2nd       Semifinals   \n",
       "7  2008         2   USL First Division            11th  Did not qualify   \n",
       "8  2009         2   USL First Division             1st       Semifinals   \n",
       "9  2010         2  USSF D-2 Pro League  3rd, USL (3rd)    Quarterfinals   \n",
       "\n",
       "          Open Cup Avg. Attendance  \n",
       "0  Did not qualify           7,169  \n",
       "1  Did not qualify           6,260  \n",
       "2  Did not qualify           5,871  \n",
       "3        4th Round           5,628  \n",
       "4        4th Round           6,028  \n",
       "5        3rd Round           5,575  \n",
       "6        2nd Round           6,851  \n",
       "7        1st Round           8,567  \n",
       "8        3rd Round           9,734  \n",
       "9        3rd Round          10,727  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pack / Setup\n",
    "\n",
    "Now we do `download_llama_pack` to load the Mix Self Consistency LlamaPack (you can also import the module directly if using the llama-hub package).\n",
    "\n",
    "We will also optionally setup observability/tracing so we can observe the intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 4 (char 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Option: if developing with the llama_hub package\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from llama_hub.llama_packs.tables.mix_self_consistency.base import (\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     MixSelfConsistencyQueryEngine,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Option: download llama_pack\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_pack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_llama_pack\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdownload_llama_pack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMixSelfConsistencyPack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./mix_self_consistency_pack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# leave the below line commented out if using the notebook on main\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllama_hub_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/run-llama/llama-hub/suo/table_qa\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchain_of_table_pack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChainOfTableQueryEngine, serialize_table\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/llama_index/llama_pack/download.py:31\u001b[0m, in \u001b[0;36mdownload_llama_pack\u001b[0;34m(llama_pack_class, download_dir, llama_hub_url, refresh_cache, skip_load)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_llama_pack\u001b[39m(\n\u001b[1;32m     13\u001b[0m     llama_pack_class: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     14\u001b[0m     download_dir: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     skip_load: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Type[BaseLlamaPack]]:\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download a single LlamaPack from Llama Hub.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        A Loader.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     pack_cls \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_llama_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllama_pack_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllama_hub_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllama_hub_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefresh_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama_packs/library.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_library_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     track_download(llama_pack_class, MODULE_TYPE\u001b[38;5;241m.\u001b[39mLLAMAPACK)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pack_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/llama_index/download/module.py:217\u001b[0m, in \u001b[0;36mdownload_llama_module\u001b[0;34m(module_class, llama_hub_url, refresh_cache, custom_dir, custom_path, library_path, base_file_name, use_gpt_index_import, disable_library_cache, override_path, skip_load)\u001b[0m\n\u001b[1;32m    214\u001b[0m dirpath \u001b[38;5;241m=\u001b[39m initialize_directory(custom_path\u001b[38;5;241m=\u001b[39mcustom_path, custom_dir\u001b[38;5;241m=\u001b[39mcustom_dir)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# fetch info from library.json file\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m module_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_module_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllama_hub_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefresh_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_library_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_library_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m module_id \u001b[38;5;241m=\u001b[39m module_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    226\u001b[0m extra_files \u001b[38;5;241m=\u001b[39m module_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_files\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/llama_index/download/module.py:69\u001b[0m, in \u001b[0;36mget_module_info\u001b[0;34m(local_dir_path, remote_dir_path, module_class, refresh_cache, library_path, disable_library_cache)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     library_raw_content, _ \u001b[38;5;241m=\u001b[39m get_file_content(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mstr\u001b[39m(remote_dir_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     )\n\u001b[0;32m---> 69\u001b[0m     library \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary_raw_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_class \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m library:\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoader class name not found in library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 4 (char 3)"
     ]
    }
   ],
   "source": [
    "# Option: if developing with the llama_hub package\n",
    "# from llama_hub.llama_packs.tables.mix_self_consistency.base import (\n",
    "#     MixSelfConsistencyQueryEngine,\n",
    "# )\n",
    "\n",
    "# Option: download llama_pack\n",
    "from llama_index.llama_pack import download_llama_pack\n",
    "\n",
    "download_llama_pack(\n",
    "    \"MixSelfConsistencyPack\",\n",
    "    \"./mix_self_consistency_pack\",\n",
    "    skip_load=True,\n",
    "    # leave the below line commented out if using the notebook on main\n",
    "    llama_hub_url=\"https://raw.githubusercontent.com/run-llama/llama-hub/suo/table_qa\"\n",
    ")\n",
    "from chain_of_table_pack.base import ChainOfTableQueryEngine, serialize_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index.query_engine.mix_self_consistency_query_engine import MixSelfConsistencyQueryEngine\n",
    "\n",
    "llm = OpenAI()\n",
    "query_engine = MixSelfConsistencyQueryEngine(\n",
    "    table=table, \n",
    "    llm=llm,\n",
    "    text_paths=1,\n",
    "    symbolic_paths=1,\n",
    "    aggregation_mode='self_evaluation',\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textual Reasoning Path 1/1\n",
      "\u001b[1;3;38;2;155;135;227m> Running module c1ca8d49-12bb-4901-84af-332f6c71d750 with input: \n",
      "title: Untitled Table\n",
      "question: what was the last year where this team was a part of the usl a-league?\n",
      "table: |    |   Year |   Division | League              | Regular Season   | Playoffs        | Open Cup        | Avg. Attendance   |\n",
      "|---:|-------:|-----------:|:--------------------|:-----------------|:----...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 0fd90385-40c5-42f8-9d44-7d3e1524ac4c with input: \n",
      "messages: You are an advanced AI capable of analyzing and understanding information within tables. Read the table below regarding \"Untitled Table\".\n",
      "\n",
      "|    |   Year |   Division | League              | Regular Se...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module a03b95e2-6925-46a5-bb80-3987183d946d with input: \n",
      "input: assistant: To determine the last year in which this team was a part of the USL A-League, we need to analyze the \"Division\" column in the table. \n",
      "\n",
      "Starting from the last row and moving upwards, we can ...\n",
      "\n",
      "\u001b[0mResponse: 2003\n",
      "Symbolic Reasoning Path 1/1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutterance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/query_engine/custom.py:45\u001b[0m, in \u001b[0;36mCustomQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     query_str \u001b[38;5;241m=\u001b[39m str_or_query_bundle\n\u001b[0;32m---> 45\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     Response(raw_response)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_response, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m raw_response\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/query_engine/mix_self_consistency_query_engine.py:330\u001b[0m, in \u001b[0;36mMixSelfConsistencyQueryEngine.custom_query\u001b[0;34m(self, query_str)\u001b[0m\n\u001b[1;32m    325\u001b[0m     text_results \u001b[38;5;241m=\u001b[39m textual_reasoning(\n\u001b[1;32m    326\u001b[0m         table, query_str, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_paths\n\u001b[1;32m    327\u001b[0m     )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_paths \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 330\u001b[0m     symbolic_results \u001b[38;5;241m=\u001b[39m \u001b[43msymbolic_reasoning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymbolic_paths\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aggregate(table, query_str, text_results, symbolic_results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregation_mode)\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/query_engine/mix_self_consistency_query_engine.py:142\u001b[0m, in \u001b[0;36msymbolic_reasoning\u001b[0;34m(table, query_str, llm, verbose, symbolic_paths)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbolic Reasoning Path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mind\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_paths\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m PandasQueryEngine(\n\u001b[1;32m    135\u001b[0m     df\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m    136\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/core/base_query_engine.py:40\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     39\u001b[0m     str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/query_engine/pandas_query_engine.py:175\u001b[0m, in \u001b[0;36mPandasQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_table_context()\n\u001b[0;32m--> 175\u001b[0m pandas_response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pandas_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstruction_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instruction_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose:\n\u001b[1;32m    183\u001b[0m     print_text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Pandas Instructions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpandas_response_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/llms/llm.py:238\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_template_data(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[0;32m--> 238\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprompt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat(messages)\n\u001b[1;32m    240\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/llms/llm.py:184\u001b[0m, in \u001b[0;36mLLM._get_messages\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_messages\u001b[39m(\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: BasePromptTemplate, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args: Any\n\u001b[1;32m    183\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[ChatMessage]:\n\u001b[0;32m--> 184\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprompt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m         messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mformat_messages(messages)\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/prompts/base.py:208\u001b[0m, in \u001b[0;36mPromptTemplate.format_messages\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt into a list of chat messages.\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m llm  \u001b[38;5;66;03m# unused\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prompt_to_messages(prompt)\n",
      "File \u001b[0;32m~/dev/llama_index/llama_index/prompts/base.py:193\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    187\u001b[0m all_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    190\u001b[0m }\n\u001b[1;32m    192\u001b[0m mapped_all_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_all_vars(all_kwargs)\n\u001b[0;32m--> 193\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmapped_all_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mformat(prompt)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "query_engine.query(example['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
